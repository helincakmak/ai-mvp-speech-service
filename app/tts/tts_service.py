import io
import wave
import logging

import numpy as np
import torch
from kokoro import KPipeline

logger = logging.getLogger(__name__)

SAMPLE_RATE = 24_000
FADE_MS = 40  # fade-in/out sÃ¼resi (robotik ses Ã¶nleme)


class TTSService:
    def __init__(self) -> None:
        """
        Kokoro TTS pipeline'Ä±nÄ± yÃ¼kler.
        Railway free planda GPU olmadÄ±ÄŸÄ± iÃ§in device doÄŸrudan 'cpu'.
        Bu sÄ±nÄ±f zaten main.py'de lazy-load edildiÄŸi iÃ§in,
        sadece ilk /tts isteÄŸinde Ã§alÄ±ÅŸacak.
        """
        try:
            logger.info("Kokoro TTS yÃ¼kleniyor...")

            # Railway'de GPU yok, doÄŸrudan CPU kullanÄ±yoruz
            device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"Device: {device}")

            self.pipeline = KPipeline(
                lang_code="a",            # Ä°ngilizce
                repo_id="hexgrad/Kokoro-82M",
                device=device,
            )

            logger.info("âœ… Kokoro TTS baÅŸarÄ±yla yÃ¼klendi!")

        except Exception as e:
            logger.error(f"âŒ Kokoro TTS yÃ¼klenirken hata: {e}")
            raise

    def text_to_speech(
        self,
        text: str,
        voice: str = "af_heart",
        speed: float = 0.9,
    ) -> bytes:
        """
        Metni sese Ã§evirir.

        Args:
            text: DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lecek metin
            voice: Ses modeli (af_heart, af_sky, af_bella, am_adam vb.)
            speed: KonuÅŸma hÄ±zÄ± (0.5â€“2.0 arasÄ±, varsayÄ±lan 0.9)

        Returns:
            WAV formatÄ±nda ses verisi (bytes)
        """
        try:
            if not text or not text.strip():
                raise ValueError("Metin boÅŸ olamaz.")

            logger.info(f"ðŸŽ¤ TTS iÅŸlemi baÅŸlÄ±yor: '{text[:50]}...'")
            logger.info(f"Voice: {voice}, Speed: {speed}")

            # Kokoro ile ses Ã¼ret
            gen = self.pipeline(
                text,
                voice=voice,
                speed=speed,
            )

            # TÃ¼m chunk'larÄ± birleÅŸtir
            audio_chunks = []
            for _, _, audio in gen:
                audio_chunks.append(np.asarray(audio, dtype=np.float32))

            if not audio_chunks:
                raise ValueError("Ses Ã¼retilemedi!")

            # Chunk'larÄ± tek array'e birleÅŸtir
            audio = np.concatenate(audio_chunks)

            # Fade-in/out uygula (robotik hissi azaltÄ±r)
            audio = self._apply_fade(audio)

            # WAV bytes'a Ã§evir
            audio_bytes = self._numpy_to_wav(audio, SAMPLE_RATE)

            audio_duration = len(audio) / SAMPLE_RATE
            logger.info(
                f"âœ… TTS baÅŸarÄ±lÄ±! Ses boyutu: {len(audio_bytes)} bytes, "
                f"SÃ¼re: {audio_duration:.2f}s"
            )

            return audio_bytes

        except Exception as e:
            logger.error(f"âŒ TTS hatasÄ±: {e}")
            raise

    def _apply_fade(self, audio: np.ndarray) -> np.ndarray:
        """
        BaÅŸÄ±na ve sonuna fade-in/out uygular (sert giriÅŸ/Ã§Ä±kÄ±ÅŸÄ± yumuÅŸatÄ±r).
        """
        audio = audio.astype(np.float32)
        n = int(SAMPLE_RATE * FADE_MS / 1000)
        n = max(1, min(n, len(audio) // 2))

        fade_in = np.linspace(0.0, 1.0, n, dtype=np.float32)
        fade_out = fade_in[::-1]

        audio[:n] *= fade_in
        audio[-n:] *= fade_out
        return audio

    def _numpy_to_wav(self, samples: np.ndarray, sample_rate: int) -> bytes:
        """
        NumPy array'i WAV bytes'a Ã§evirir.
        """
        # Float32'den Int16'ya Ã§evir
        audio_int16 = (samples * 32767).astype(np.int16)

        # WAV dosyasÄ±nÄ± memory'de oluÅŸtur
        wav_io = io.BytesIO()
        with wave.open(wav_io, "wb") as wav_file:
            wav_file.setnchannels(1)   # Mono
            wav_file.setsampwidth(2)   # 16-bit
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_int16.tobytes())

        return wav_io.getvalue()
